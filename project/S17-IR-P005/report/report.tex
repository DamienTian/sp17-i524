\documentclass[9pt,twocolumn,twoside]{../../styles/osajnl}
\usepackage{fancyvrb}
\journal{i524} 

\title{Analysis Of People Relationship Using Word2Vec on Wiki Data}

\author[1,*]{Abhishek Gupta}
\author[1, **]{Avadhoot Agasti}

\affil[1]{School of Informatics and Computing, Bloomington, IN 47408, U.S.A.}

\affil[*]{Corresponding authors: abhigupt@iu.edu}
\affil[**]{Corresponding authors: aagasti@iu.edu}

\dates{project-1: Data mining for a wiki url , \today}

\ociscodes{Cloud, I524, Chemeleon, Word2Vec, Jetstream, Cloudmesh, RAM}

% replace this with your url in github/gitlab
\doi{Report: \url{https://github.com/cloudmesh/sp17-i524/blob/master/project/S17-IR-P005/report/report.pdf}\\
     Code: \url{https://github.com/cloudmesh/cloudmesh.word2vec}}

\begin{abstract}
Wikipedia pages of famous personalities contain details like school, spouse,
coaches, languages, alma-meter etc. This information is in free form text. In
 this project, we extract the people information from the Wikipedia page and
 to establish relationships between them. Specifically, we use the data of
 known relationships to derive the newer relationships.
\end{abstract}

\setboolean{displaycopyright}{true}


\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

Word2Vec \cite{www-word2vec} is a group of related models that are used to
produce word embedding. Word2Vec is used to analyze the linguistic context
of the words. In this project, we created Word2vec model using Wikipedia data
and news articles.  Our focus is people names occurring in the
Wikipedia data and to see if Word2vec can be used to understand relationship
 between people. Typically Wikipedia page for people and celebrities contain
  the entire family and friends, colleagues information. Our idea is to use
  Word2vec to see if using a smaller training set of known relationships
  whether we can derive similar relationship for anyone who has presence on
  Wikipedia. This mechanism can be then used to convert the data hidden in
  textual format to more structured data.

We used spark \cite{www-spark-python} to load the wiki data and create word
vectors. We then used vector manipulations to derive the relationships.

\begin{table}[h!]
\centering
\begin{tabular}{||c c||} 
 \hline
 Name & Purpose \\ [0.5ex] 
 \hline\hline
spark \cite{www-spark-python} & data analysis \\ 
 sparkML \cite{www-sparkml} & machine learning  \\ 
 python \cite{www-spark-python} & development  \\ 
 ansible \cite{www-ansible} & automated deployment \\ [1ex] 
 \hline
\end{tabular}
\caption{Technology Name and Purpose}
\label{table:1}
\end{table}

%\section{Design}
%TBD
\input{design}

\input{deployment}

\input{benchmarking}

\section{Discussion}
The analysis of the results provided interesting insights.
Section \ref{appdiscussion} provides key insights on our experiments with
Word2Vec on Wikipedia data. Section \ref{deploymentdiscussion} provide key
insights on our experience of deployment and execution of Word2Vec
application on Chameleon and Jetstream cloud.
\input{appdiscussion} \label{appdiscussion}
\input{deploymentdiscussion} \label{deploymentdiscussion}

\section{Conclusion}

Using this project we conclude that we can use Word2Vev model on Wikipedia
and news data to find the relationships between the people.

We further conclude that Word2Vec based analytics can be performed on public
cloud systems like Chameleon cloud and Jetstream cloud. Our deployment
automation, which is implemented using Cloudmesh and Ansible technology
demonstrates the power of these technologies to achieve one touch deployment
and execution of applications across multiple clouds.

\section{Acknowledgement}

We acknowledge our professor Gregor von Laszewski and all associate instructors for helping us and guiding us throughout this project.

\section{Appendices}
Appendix A: Work Distribution
The co-authors of this report worked together on the design of the technical
solutions, implementation, testing and documentation. Below given is the work
 distribution
\begin{itemize}
\item Avadhoot Agasti
    \begin{itemize}
    \item Implementation of wiki crawler and news cralwer in Python.
    \item Implementation of CreateWord2VecModel in Spark.
    \item Implementation of UseWord2VecModel and FindRelations in Spark.
    \item Implementation of Python script MonitorSparkApp.
    \item Analyzing the Word2Vec model results.
    \item Testing of end to end flow on Chameleon cloud.
    \item Performance testing and bug fixing in the spark application.
    \item Writing related sections in this report.
    \end{itemize}

\item Abhishek Gupta
    \begin{itemize}
    \item Implementation of Ansible scripts for deployment of Spark 2.1 which
     is required for the spark application.
    \item Implementation of Ansible scripts for deployment.
    \item Implementing the changes in the spark applications to get it
    working on HDFS.
    \item Setting up and testing the end to end flow on Chameleon cloud.
    \item Setting up and testing the end to end flow on Jetstream cloud.
    \item Testing the crawler and Word2Vec applications for semantic
    correctness.
    \item Gathering the perfomance statistics for comparison.
    \item Writing related sections in this report.
    \end{itemize}
\end{itemize}

% Bibliography

\bibliography{references}

\end{document}
